{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vaceslavefimov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vaceslavefimov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ребят, привет! заранее извиняюсь, если пишу не...</td>\n",
       "      <td>ребята привет заранее извиняться писать нужный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>привет!\\n*позиция:* team lead (data science)\\n...</td>\n",
       "      <td>привет позиция компания лаборатория искусствен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>всем привет!\\nищу в свою команду big data инже...</td>\n",
       "      <td>весь привет искать команда инженер компания пл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>эта вакансия для тех, кто хочет *решать соревн...</td>\n",
       "      <td>этот вакансия тот хотеть решать соревнование р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*компания:* сбербанк\\n*вакансия:* data scienti...</td>\n",
       "      <td>компания сбербанк вакансия город москва вилка ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>дружественная нам исследовательская группа нан...</td>\n",
       "      <td>дружественный мы исследовательский группа нани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>мопед не мой, так что все вопросы по указанном...</td>\n",
       "      <td>мопед вопрос указанный коллега попросить отпра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>отношения никакого к университету не имею, но ...</td>\n",
       "      <td>отношение никакой университет иметь решить под...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>всем привет!\\nу нас в гренобльском офисе crite...</td>\n",
       "      <td>весь привет гренобльский офис открыться позици...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>коллеги из роттердама ищут phd студентов с хор...</td>\n",
       "      <td>коллега роттердам искать студент хороший скил ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3745 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     ребят, привет! заранее извиняюсь, если пишу не...   \n",
       "1     привет!\\n*позиция:* team lead (data science)\\n...   \n",
       "2     всем привет!\\nищу в свою команду big data инже...   \n",
       "3     эта вакансия для тех, кто хочет *решать соревн...   \n",
       "4     *компания:* сбербанк\\n*вакансия:* data scienti...   \n",
       "...                                                 ...   \n",
       "3740  дружественная нам исследовательская группа нан...   \n",
       "3741  мопед не мой, так что все вопросы по указанном...   \n",
       "3742  отношения никакого к университету не имею, но ...   \n",
       "3743  всем привет!\\nу нас в гренобльском офисе crite...   \n",
       "3744  коллеги из роттердама ищут phd студентов с хор...   \n",
       "\n",
       "                                        normalized_text  \n",
       "0     ребята привет заранее извиняться писать нужный...  \n",
       "1     привет позиция компания лаборатория искусствен...  \n",
       "2     весь привет искать команда инженер компания пл...  \n",
       "3     этот вакансия тот хотеть решать соревнование р...  \n",
       "4     компания сбербанк вакансия город москва вилка ...  \n",
       "...                                                 ...  \n",
       "3740  дружественный мы исследовательский группа нани...  \n",
       "3741  мопед вопрос указанный коллега попросить отпра...  \n",
       "3742  отношение никакой университет иметь решить под...  \n",
       "3743  весь привет гренобльский офис открыться позици...  \n",
       "3744  коллега роттердам искать студент хороший скил ...  \n",
       "\n",
       "[3745 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем обработанный датасет из предыдущей лабораторной работы\n",
    "df = pd.read_csv('LW4/jobs.csv')[['text', 'normalized_text']]\n",
    "\n",
    "df['normalized_text'] = df['normalized_text'].map(lambda tokens: ' '.join(eval(tokens)))\n",
    "\n",
    "# удалим пустые документы\n",
    "df = df[df['normalized_text'].map(lambda tokens: len(tokens)) > 0].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spelling(text: str):\n",
    "    \"\"\"\n",
    "    Исправляет опечатки слов в тексте с помощью Yandex Spellchecker API\n",
    "    param text: текст, в котором нужно исправить опечатки\n",
    "    \"\"\"\n",
    "    \n",
    "    domain = \"https://speller.yandex.net/services/spellservice.json\"\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        request = requests.get(domain + \"/checkText?text=\" + words[0])\n",
    "        if request.json():\n",
    "            return request.json()[0][\"word\"], request.json()[0][\"s\"]\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    elif len(words) > 1:\n",
    "        words = \"+\".join(words)\n",
    "        request = requests.get(domain + \"/checkText?text=\" + words)\n",
    "        if request.json():\n",
    "            response = [(i[\"word\"], i[\"s\"]) for i in request.json()]\n",
    "            return response\n",
    "        else:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def edit_spelling(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Редактирует текст, исправляя в нем опечатки. В случае если не удалось найти в корпусе Yandex заданное слово,\n",
    "    оно не изменяется.\n",
    "    param query: текст для редактиврования\n",
    "    \"\"\"\n",
    "    \n",
    "    edited_words = []\n",
    "    words = query.split()\n",
    "    for word in words:\n",
    "        edited_word = check_spelling(word)\n",
    "        edited_words.append(word if edited_word is None else edited_word[1][0])\n",
    "    return ' '.join(edited_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Преобразует текст в список слов, удаляя в нем символы пунктуации, цифры и другие лишние символы\n",
    "    param text: текст для преобразования\n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub(r\"http[s]?://(?:[а-яА-Я]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", text)\n",
    "    text = re.sub(\"[^а-яА-Я]\",\" \", text)\n",
    "    return text.lower().split()\n",
    "\n",
    "\n",
    "def remove_stopwords(words: list) -> list:\n",
    "    \"\"\"\n",
    "    Удаляет стоп-слова\n",
    "    param words: список слов, в которых нужно удалить стоп-слова\n",
    "    \"\"\"\n",
    "    \n",
    "    return [w for w in words if not w in stopwords.words('russian')]\n",
    "\n",
    "\n",
    "def process_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    param text: токенизируемый текст\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_texts = tokenizer.tokenize(text.strip())\n",
    "    texts = []\n",
    "    for raw_text in raw_texts:\n",
    "        if len(raw_text) > 0:\n",
    "            texts.append(remove_stopwords(text_to_wordlist(raw_text)))\n",
    "    return [item for sublist in texts for item in sublist]\n",
    "\n",
    "\n",
    "def normalize(token: str) -> str:\n",
    "    \"\"\"\n",
    "    Нормализация токена\n",
    "    param token: токен\n",
    "    \"\"\"\n",
    "    \n",
    "    return morph.parse(token)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Редактирование запроса. Включает в себя следующие шаги:\n",
    "    1. Исправление опечаток\n",
    "    2. Токенизация\n",
    "    3. Удаление стоп-слов\n",
    "    4. Нормализация\n",
    "    \"\"\"\n",
    "    return ' '.join(list(map(lambda word: normalize(word), process_text(edit_spelling(query)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Информационный поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a: list, b: list) -> np.float64:\n",
    "    \"\"\"\n",
    "    Считает косинусное расстояние между векторами\n",
    "    param a, b: векторы\n",
    "    \"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(corpus: pd.Series, query: str, top_n: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Возвращает наиболее похожие тексты на основании запроса\n",
    "    param df: датафрейм, содержащий тексты\n",
    "    param query: текст, для которого нужно сделать рекомендацию. Возвращает список индексов в датасете df\n",
    "    param top_n: количество рекомендуемых текстов\n",
    "    \"\"\"\n",
    "    \n",
    "    query = process_query(query)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorized_texts = list(vectorizer.fit_transform(list(corpus) + [query]).toarray())\n",
    "    vectorized_corpus = vectorized_texts[:-1]\n",
    "    vectorized_query = vectorized_texts[-1]\n",
    "    \n",
    "    recommendations = sorted(enumerate(vectorized_corpus), key=lambda text: cosine(text[1], vectorized_query))\n",
    "    return [index for index, text in recommendations[-top_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>всем привет!\\nесть здесь ребята из минска, кот...</td>\n",
       "      <td>весь привет ребята минск который начинать свой...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>всем привет!\\nмы в ringlabs в киев очень ищем ...</td>\n",
       "      <td>весь привет киев очень искать наш отдел задача...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>всем привет!\\nпитер, нужен nlp - специалист!\\n...</td>\n",
       "      <td>весь привет питер нужный специалист ссылка вак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>:lamoda: команда r&amp;amp;d lamoda ~продала много...</td>\n",
       "      <td>команда продать трусель очень вести прошлый го...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>:lamoda: команда r&amp;amp;d lamoda ~продала много...</td>\n",
       "      <td>команда продать трусель очень вести прошлый го...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>:v:всем привет! у нас еще актуальна вакансия!\\...</td>\n",
       "      <td>весь привет актуальный вакансия искать собрать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>друзья, привет!\\n\\nкомпания :ice_hockey_stick_...</td>\n",
       "      <td>друг привет компания искать собрать команда пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>*midlle/senior analyst, operation efficiency*\\...</td>\n",
       "      <td>компания лента ленточка локация москва зарплат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>добрый день! \\n\\n\\nдолжность: data analyst\\nко...</td>\n",
       "      <td>добрый день должность компания лента локация м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>в молодой амбициозный старт-ап &lt;http://fabriqu...</td>\n",
       "      <td>молодой амбициозный старт ап требоваться созда...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "672   всем привет!\\nесть здесь ребята из минска, кот...   \n",
       "333   всем привет!\\nмы в ringlabs в киев очень ищем ...   \n",
       "460   всем привет!\\nпитер, нужен nlp - специалист!\\n...   \n",
       "2139  :lamoda: команда r&amp;d lamoda ~продала много...   \n",
       "3395  :lamoda: команда r&amp;d lamoda ~продала много...   \n",
       "517   :v:всем привет! у нас еще актуальна вакансия!\\...   \n",
       "3230  друзья, привет!\\n\\nкомпания :ice_hockey_stick_...   \n",
       "2070  *midlle/senior analyst, operation efficiency*\\...   \n",
       "2275  добрый день! \\n\\n\\nдолжность: data analyst\\nко...   \n",
       "1762  в молодой амбициозный старт-ап <http://fabriqu...   \n",
       "\n",
       "                                        normalized_text  \n",
       "672   весь привет ребята минск который начинать свой...  \n",
       "333   весь привет киев очень искать наш отдел задача...  \n",
       "460   весь привет питер нужный специалист ссылка вак...  \n",
       "2139  команда продать трусель очень вести прошлый го...  \n",
       "3395  команда продать трусель очень вести прошлый го...  \n",
       "517   весь привет актуальный вакансия искать собрать...  \n",
       "3230  друг привет компания искать собрать команда пр...  \n",
       "2070  компания лента ленточка локация москва зарплат...  \n",
       "2275  добрый день должность компания лента локация м...  \n",
       "1762  молодой амбициозный старт ап требоваться созда...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Привет! Нам нушен в старт-ап классныъ разрабачик данных'\n",
    "recommendation_indices = recommend(df['normalized_text'], query)\n",
    "df.loc[recommendation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
